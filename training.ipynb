{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ProcessGroupGloo.cpp:751] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets import load_dataset\n",
    "from llama.tokenizer import Tokenizer\n",
    "\n",
    "from mixture_of_depths.routing_transformer import ModelArgs, MoDTransformer\n",
    "from mixture_of_depths.train import MoDLlamaTrainer\n",
    "from mixture_of_depths.utils import set_up_env\n",
    "\n",
    "random_state = 88\n",
    "set_up_env(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"igorktech/anekdots\", split=\"train\")\n",
    "num_of_samples = 20000\n",
    "dataset = dataset.select(range(num_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\"tokenizer.model\") # follow instruction to load \n",
    "text_length_max = 64\n",
    "def collate_fn(batch):\n",
    "    bsz = len(batch)\n",
    "    tokenized_texts = [tokenizer.encode(x['text'], bos=True, eos=True) for x in batch]\n",
    "    max_text_len = max(len(t) for t in tokenized_texts)\n",
    "\n",
    "    pad_id = tokenizer.eos_id\n",
    "    tokens = torch.full((bsz, min(text_length_max, max_text_len)), pad_id, dtype=torch.long)\n",
    "    for k, t in enumerate(tokenized_texts):\n",
    "        tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long)[:text_length_max]\n",
    "    \n",
    "    return tokens[:,:-1], tokens[:,1:]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.794432 M parameters\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelArgs(\n",
    "    dim=256,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    vocab_size=tokenizer.n_words,\n",
    "    routing=True,\n",
    "    aux_loss=True\n",
    ")\n",
    "model = MoDTransformer(model_params)\n",
    "writer = SummaryWriter(log_dir='runs/MoD')\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MoDLlamaTrainer(\n",
    "    params=model_params,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataloader=dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  40%|████      | 1001/2500 [02:34<03:50,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 4.983256434202194\n",
      "Causal Loss at step 1000: 0.0024631750199141608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  80%|████████  | 2001/2500 [05:09<01:18,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 4.061281044125557\n",
      "Causal Loss at step 2000: 0.0013510382889885477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 2500/2500 [06:25<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 3.7215605016708375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  40%|████      | 1001/2500 [02:34<03:53,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.3142513897418975\n",
      "Causal Loss at step 1000: 7.633750385866734e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  80%|████████  | 2001/2500 [05:08<01:19,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.3842985979914664\n",
      "Causal Loss at step 2000: 8.665982752245327e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 2500/2500 [06:27<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss: 2.4195097153663636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  40%|████      | 1001/2500 [02:36<03:56,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.2019019101858137\n",
      "Causal Loss at step 1000: 0.000135026712607214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  80%|████████  | 2001/2500 [05:08<01:13,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.0999294768571852\n",
      "Causal Loss at step 2000: 0.0001003341482801261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 2500/2500 [06:24<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss: 2.081954874229431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  40%|████      | 1001/2500 [02:34<03:44,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 1.9111106233596802\n",
      "Causal Loss at step 1000: 2.0166175017038767e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  80%|████████  | 2001/2500 [05:07<01:12,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 1.8612041330337525\n",
      "Causal Loss at step 2000: 1.9162412942023367e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 2500/2500 [06:23<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss: 1.8424236430168153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5:  40%|████      | 1001/2500 [02:34<03:59,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 1.6624065164327622\n",
      "Causal Loss at step 1000: 1.0917767894625286e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5:  80%|████████  | 2001/2500 [05:06<01:18,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 1.6389817885160447\n",
      "Causal Loss at step 2000: 1.1160827034245812e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 2500/2500 [06:25<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss: 1.6381528455257415\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=5,\n",
    "    lr=3e-4,\n",
    "    use_aux_loss=model_params.aux_loss,\n",
    "    use_aux_predictor=model.params.aux_routing, \n",
    "    model_dir='models/MoDLlama',\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.794176 M parameters\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelArgs(\n",
    "    dim=256,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    vocab_size=tokenizer.n_words,\n",
    "    routing=False,\n",
    "    aux_loss=False\n",
    ")\n",
    "writer = SummaryWriter(log_dir='runs/Llama')\n",
    "model = MoDTransformer(model_params)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MoDLlamaTrainer(\n",
    "    params=model_params,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataloader=dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  40%|████      | 1001/2500 [02:23<03:28,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 5.0363804886341095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:  80%|████████  | 2001/2500 [04:49<01:14,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 4.484910386323929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 2500/2500 [06:01<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 4.320811706161499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  40%|████      | 1001/2500 [02:24<03:33,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 3.4606797211170197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:  80%|████████  | 2001/2500 [04:48<01:08,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 3.3693976508378984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 2500/2500 [06:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss: 3.334313145637512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  40%|████      | 1001/2500 [02:27<03:44,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 3.0729157400131224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  80%|████████  | 2001/2500 [04:52<01:08,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 3.012603771328926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 2500/2500 [06:05<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss: 2.9882658170700074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  40%|████      | 1001/2500 [02:30<04:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.8174964728355407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  80%|████████  | 2001/2500 [05:03<01:12,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.768199549973011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 2500/2500 [06:20<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss: 2.749541953134537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5:  40%|████      | 1001/2500 [02:36<03:56,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1000: 2.656064735889435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5:  80%|████████  | 2001/2500 [05:07<01:14,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 2000: 2.626405920088291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 2500/2500 [06:23<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss: 2.6183425469875337\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=5,\n",
    "    lr=3e-4,\n",
    "    use_aux_loss=model_params.aux_loss,\n",
    "    use_aux_predictor=model.params.aux_routing, \n",
    "    model_dir='models/Llama',\n",
    "    writer=writer\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
