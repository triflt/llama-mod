{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixture_of_depths.generation import MoDLlama\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 0.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ProcessGroupGloo.cpp:751] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n"
     ]
    }
   ],
   "source": [
    "generator = MoDLlama.build(\n",
    "    ckpt_dir=\"models/Llama/\",\n",
    "    tokenizer_path=\"tokenizer.model\",\n",
    "    max_seq_len=128,\n",
    "    max_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Смешно, когда никто не сказал:\n",
       "- Ой, у меня проблема. Я уже не хочу.\n",
       "- Ну и как?\n",
       "- Нет, я тебя сказал, что я тебя сделаю, что я не могу.\n",
       "- Ну и как же?\n",
       "- Неужели!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 857 ms, sys: 704 ms, total: 1.56 s\n",
      "Wall time: 349 ms\n"
     ]
    }
   ],
   "source": [
    "# 19 M parameters on 20k samples\n",
    "%%time\n",
    "text = \"\\nСмешно, когда \"\n",
    "answer = generator.text_completion([text], temperature=0.5)[0]['generation']\n",
    "display(Markdown(text + answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
